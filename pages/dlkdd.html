<!DOCTYPE html>
<html lang="en">

<head>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Qahiri&display=swap" rel="stylesheet">
    <link href="/styles/try.CSS" rel="stylesheet" type="text/css">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-GLhlTQ8iRABdZLl6O3oVMWSktQOp6b7In1Zl3/Jr59b6EGGoI1aFkw7cmDA6j6gD" crossorigin="anonymous">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/sql.js/1.8.0/sql-wasm.js"></script>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DL-KDD: Dual-Lightness Knowledge Distillation for Action Recognition in the Dark</title>
</head>

<body>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js" integrity="sha384-w76AqPfDkMBDXo30jS1Sgez6pr3x5MlQ1ZAGC+nuZB+EYdgRZgiwxhTBTkF7CXvN" crossorigin="anonymous"></script>
    <div id="topbar"><nav class="navbar navbar-expand-lg bg-body-tertiary">
        <div class="container-fluid">
          <a class="navbar-brand" href="/index.html">Jerryyyyy708</a>
          <div class="collapse navbar-collapse">
            <ul class="navbar-nav me-auto mb-2 mb-lg-0">
            </ul>
            <button class="btn btn-dark" type="submit" id="back" onclick="location.href='/index.html'">Back</button>
          </div>
        </div>
    </nav></div>
    
    <div class="container-fluid min-vh-100 d-flex flex-column p-0"> 
        <div class="d-flex flex-row flex-grow-1 mb-2">
            <div class="d-flex flex-column flex-shrink-0 p-3" style = "width: 253px" id = "leftrow"></div>
            <script src="/scripts/sidebar.js"></script>
            <div class="d-flex flex-column flex-shrink-0 p-3 main-content">
                <div>
                    <h3 class="pj_title">DL-KDD: Dual-Lightness Knowledge Distillation for Action Recognition in the Dark</h3>
                </div>
                <Br>
                <h4>Paper Source</h4>
                <p>This work is officially accepted by <b>IJCAI 2025</b> in the AI4Tech track (18% acceptance rate). 
                    <br> The preprint can be found here: <a href="https://arxiv.org/abs/2406.02468">arXiv</a> / <a href="https://ijcai-preprints.s3.us-west-1.amazonaws.com/2025/8620.pdf">IJCAI Preprint</a> 
                    and will be appear in IJCAI 2025 proceeding soon.
                </p>
                <h4>Abstract</h4>
                <p class="abstract-text">Human action recognition in dark videos is a challenging task for computer vision due to the low
                    quality of the videos filmed in the dark. Recent studies focused on applying dark enhancement methods to improve the visibility of the
                    video. However, such video processing results
                    in the loss of critical information in the original
                    (un-enhanced) video. Conversely, traditional twostream methods are capable of learning information from both original and enhanced videos, but
                    it can lead to a significant increase in the computational cost. To address these challenges, we propose a novel knowledge-distillation-based framework, named <em>Dual-Lightness KnowleDge Distillation (DL-KDD)</em>, which simultaneously resolves the
                    aforementioned issues by enabling a student model
                    to obtain both original features and light-enhanced
                    knowledge without additional complexity, thus improving the performance of the model and avoiding extra computational cost. Through comprehensive evaluations, the proposed DL-KDD, with only
                    original video required as input during the inference phase, significantly outperforms state-of-theart methods on the widely-used dark video datasets.
                    The results highlight the excellence of our proposed knowledge-distillation-based framework for
                    dark video human action recognition.</p>
                <br>
                <h4>Oral Presentation</h4>
                <p>
                    We presented the paper in IJCAI 2025, Montreal. <br>
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/jVDtmPAAM5E?si=vPe3MF6ydAxEATfG" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                </p>
                
                <h4>Poster Presentation</h4>
                <p>This work is also presented in a poster session in IJCAI 2025, Montreal.</p>
                <embed src="/src/DLKDD Poster.pdf#toolbar=0" type="application/pdf" width=540 height=770>
                <br>

                    <h4>Citation (Temporary)</h4>
                    <p>If you find our work helpful, please cite this paper as:</p>
                    <textarea readonly class="form-control" rows="10" style="text-align: left;">
@misc{chang2024dlkddduallightknowledgedistillation,
        title={DL-KDD: Dual-Light Knowledge Distillation for Action Recognition in the Dark}, 
        author={Chi-Jui Chang and Oscar Tai-Yuan Chen and Vincent S. Tseng},
        year={2024},
        eprint={2406.02468},
        archivePrefix={arXiv},
        primaryClass={cs.CV},
        url={https://arxiv.org/abs/2406.02468}, 
    }
                    </textarea>
            </div>            
        </div>
    </div>

</body>
</html>
